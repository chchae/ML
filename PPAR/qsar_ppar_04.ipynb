{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"qsar_ppar_04.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyOXjROPpEhnwt+6akqCEU2F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tUjbc2TCVb9c","colab_type":"text"},"source":["## Initialize RDKit environment"]},{"cell_type":"code","metadata":{"id":"lLmIRfXnGz-a","colab_type":"code","colab":{}},"source":["! wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","! chmod +x Miniconda3-latest-Linux-x86_64.sh\n","! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","! conda install -q -y -c rdkit rdkit\n","\n","import sys\n","sys.path.append('/usr/local/lib/python3.7/site-packages/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kqf4pCXelFRm","colab_type":"code","colab":{}},"source":["!pip install git+https://github.com/keras-team/keras-tuner.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DhpGJC1PGpSb","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","from sklearn.model_selection import train_test_split\n","import warnings , os, re\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","import tensorflow as tf\n","\n","import tensorflow.keras as keras\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from keras.utils import np_utils\n","\n","from kerastuner.tuners import RandomSearch, BayesianOptimization\n","from kerastuner.engine.hypermodel import HyperModel\n","from kerastuner.engine.hyperparameters import HyperParameters, Choice\n","\n","from rdkit import Chem, rdBase\n","from rdkit.Chem import DataStructs, AllChem, RDConfig, rdMolDescriptors\n","\n","#tf.get_logger().setLevel(logging.ERROR)\n","#tf.get_logger().setLevel('INFO')\n","#tf.autograph.set_verbosity(1)\n","\n","np.set_printoptions(precision=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wbDNCzu58F3j","colab_type":"text"},"source":["## Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"fO9Dz7yX8C9_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANHXu78JLkW8","colab_type":"text"},"source":["## Subroutines"]},{"cell_type":"code","metadata":{"id":"KJtZ3XONHdyi","colab_type":"code","colab":{}},"source":["def readMolecule( sdfname ) :\n","    moles = Chem.rdmolfiles.SDMolSupplier( sdfname )\n","    return moles\n","\n","def removeInactiveMolecules( moles, actname ) :\n","    moles = [ m for m in moles if None != m.GetProp( actname ) and float( m.GetProp( actname ) ) > 0 ]\n","    return moles\n","\n","def getFingerprintFromMolecule( moles, nBits=2048 ) :\n","    fps = [ rdMolDescriptors.GetMorganFingerprintAsBitVect( m, 2, nBits=nBits ) for m in moles ]\n","    np_fps = []\n","    for fp in fps:\n","        arr = np.zeros( ( 1, ) )\n","        #DataStructs.ConvertToNumpyArray( fp, arr )\n","        DataStructs.cDataStructs.ConvertToNumpyArray( fp, arr )\n","        np_fps.append( arr )\n","    return np.array( np_fps )\n","\n","\n","def isActivityClass( m, activity ) :\n","    if re.search( activity, m.GetProp( 'Assay Description' ), re.IGNORECASE ) :\n","        return True\n","    return False\n","\n","def findAgonist( moles ) :\n","    moles = [ m for m in moles if 'AGONIST' == m.GetProp( 'activity_class' ) ]\n","    return moles\n","\n","def findAntagonist( moles ) :\n","    moles = [ m for m in moles if 'ANTAGONIST' == m.GetProp( 'activity_class' ) ]\n","    return moles\n","\n","\n","\n","def getActivityOfMolecule( moles, actname ) :\n","    activity = [ m.GetProp( actname ) for m in moles ]\n","    activity = np.asarray( activity ).astype( 'float' )\n","    return activity\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6xBy2XCLwGz","colab_type":"text"},"source":["## DNN"]},{"cell_type":"code","metadata":{"id":"Jk_NhHf_pZmE","colab_type":"code","colab":{}},"source":["def prepareMoleculeFingerprint( path, nBits=2048 ) :\n","    sdfname = path + \"200403-PPARg-ChEMBL-6101.sdf\"\n","    actname = \"pChEMBL_Value\"\n","    moles = readMolecule( sdfname )\n","    num_load = len(moles)\n","    moles = removeInactiveMolecules( moles, actname )\n","    num_active = len(moles)\n","    # moles = findAgonist( moles )\n","    num_class = len(moles)\n","    print( \"\\n--->%d-moles loaded, %d-moles with pChEMBL_VALUE, %d-moles with activity_class\\n\" % (num_load, num_active, num_class ) )\n","\n","    x = getFingerprintFromMolecule( moles, nBits=nBits )\n","    y = getActivityOfMolecule( moles, actname )\n","\n","    return x,y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGSsklgRNLtS","colab_type":"code","colab":{}},"source":["def make_model( nfeatures=128 ):\n","    model = Sequential()\n","    model.add( Dense( nfeatures, input_dim=nfeatures, activation='relu' ) )\n","    model.add( Dense( nfeatures, activation='relu' ) )\n","    model.add( Dense(1) )\n","    model.compile( loss='mean_squared_error', optimizer='adam', metrics=['mae' ] )\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecCXQwLNVn5X","colab_type":"code","colab":{}},"source":["def plot_scatter( Y_train, Y_train_pred, Y_validation, Y_valid_pred ) :\n","    plt.figure(figsize=(6,6))\n","    plt.scatter(Y_train, Y_train_pred, color='black', s=2, label='training' )\n","    plt.scatter(Y_validation, Y_valid_pred, color='red', s=3, label='validation' )\n","    plt.xlabel( 'Experimental pIC50', labelpad=10 )\n","    plt.ylabel( 'Predicted pIC50', labelpad=10 )\n","    plt.xticks( np.arange( 2, 13 ) )\n","    plt.yticks( np.arange( 2, 13 ) )\n","    plt.savefig( 'qsar-scatter.png' )\n","\n","def plot_history( history, filename='qsar-metric.png' ):\n","    _, loss_ax = plt.subplots( figsize=(6, 4 ) )\n","    loss_ax.set_ylim( [ 0, 4 ] )\n","    acc_ax = loss_ax.twinx()\n","\n","    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n","    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n","    loss_ax.set_xlabel('epoch')\n","    loss_ax.set_ylabel('loss')\n","    loss_ax.legend(loc='upper left')\n","\n","    acc_ax.plot(history.history['mae'], 'b', label='train MAE')\n","    acc_ax.plot(history.history['val_mae'], 'g', label='val MAE')\n","    acc_ax.set_ylabel('MAE')\n","    acc_ax.legend(loc='upper right')\n","\n","    plt.savefig( filename )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjLiGlU1HgbA","colab_type":"code","colab":{}},"source":["def do_regression( model, X_train, Y_train, X_validation, Y_validation, epochs=50, batch=32, graph=False ):\n","    hist = model.fit( X_train, Y_train, epochs=epochs, batch_size=batch, validation_split=0.2, verbose=0, callbacks=[  ] )\n","    loss_and_metric = model.evaluate( X_validation, Y_validation, verbose=0 )\n","\n","    if( graph == True ) :\n","        #predictions = model.predict( X_validation )\n","        #print( hist.history.keys() )\n","        plot_history( hist )\n","\n","        Y_train_pred = model.predict(X_train).flatten()\n","        Y_valid_pred = model.predict(X_validation).flatten()\n","        plot_scatter( Y_train, Y_train_pred, Y_validation, Y_valid_pred )\n","\n","    return loss_and_metric, hist\n","\n","\n","def gridsearch( x, y, model ) :\n","    epochs = 30\n","    batchs = [ 16, 32, 64, 128, 256, 512 ]\n","\n","    maxiter=10\n","    results = []\n","    for frac_test in np.arange( 0.1, 0.9, 0.1 ) :\n","        for batch in batchs :\n","            print( \"===>frac_test=%.1f, batchsize=%2d\" % ( frac_test, batch ) )\n","            for _ in np.arange(0, maxiter) :\n","                x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=frac_test )\n","                loss_and_metric, hist = do_regression( model, x_train, y_train, x_test, y_test, epochs, batch=batch )\n","                results.append( loss_and_metric )\n","                print( '%.1f, %3d : %.3f %.3f' % (frac_test, batch, loss_and_metric[0], loss_and_metric[1]), ' : ', \"%.3f\" % hist.history['loss'][-1], ', ', \"%.3f\" % hist.history['val_loss'][-1] )\n","\n","    plt.figure( figsize=( 8, 6 ) )\n","    plt.ylim( 0, 1 )\n","    plt.plot( results, label=( [ 'loss', 'mae' ] ) )\n","    plt.savefig( 'qsar-metric-all.png' )\n","    return\n","\n","\n","\n","def train( x, y, model, epochs = 50, batch = 64 ) :\n","    hist = model.fit( x, y, epochs=epochs, batch_size=batch, validation_split=0.2, verbose=1, callbacks=[] )\n","    plot_history( hist, 'qsar-train.png' )\n","    return model\n","\n","\n","def predict( model, sdfname ) :\n","    biocides = readMolecule( sdfname )\n","    x = getFingerprintFromMolecule( biocides, nBits=128 )\n","    y = model.predict(x).flatten()\n","    print(y)\n","    return y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPV-MfmC3oSQ","colab_type":"code","colab":{}},"source":["def parameter_gridsearch( x, y ) :\n","    nBits = x.shape[1]\n","\n","    strategy = tf.distribute.MirroredStrategy()\n","    # print('\\n===>Number of devices: {}\\n'.format(strategy.num_replicas_in_sync))\n","\n","    with strategy.scope() :\n","        model = make_model( nfeatures=nBits )\n","\n","    maxiter=10\n","    epochs=50\n","    frac_tests = np.arange( 0.1, 0.9, 0.1 )\n","    batches = [ 16, 32, 64, 128, 256, 512 ]\n","    history = []\n","    for frac_test in frac_tests :\n","        for batch in batches :\n","            for _ in np.arange(0, maxiter) :\n","                hist = model.fit( x, y, epochs=epochs, batch_size=batch, validation_split=frac_test, verbose=0, callbacks=[  ] )\n","                history.append( [ hist.history['loss'][-1], hist.history['val_loss'][-1] ] )\n","\n","    history = np.array(history)\n","    print( history )\n","\n","    plt.figure( figsize=( 8, 6 ) )\n","    plt.ylim( 0, 1 )\n","    plt.plot( history[:,0], label='loss' )\n","    plt.plot( history[:,1], label='val_loss' )\n","    plt.savefig( 'qsar-metric-all.png' )\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5IS3C4BoeWA","colab_type":"code","colab":{}},"source":["def make_optimizer_model( nfeatures ) :\n","    # LR = Choice( 'learning_rate', values=[1e-2, 1e-3, 1e-4] )\n","    # MOMENTUM = Choice('momentum', values=[0.0, 0.2, 0.4, 0.6, 0.8, 0.9])\n","    optimizers = Choice('optimizer', values=['adam', 'sgd', 'rmsprop'] )\n","\n","    model = Sequential()\n","    model.add( Dense( nfeatures, input_dim=nfeatures, activation='relu' ) )\n","    model.add( Dense( nfeatures, activation='relu' ) )\n","    model.add( Dense(1) )\n","    # model.compile( loss='mean_squared_error', optimizer=optimizers, metrics=['mae' ] )\n","    # model.compile( loss='mean_squared_error', optimizer=keras.optimizers.SGD( LR, momentum=MOMENTUM ), metrics=['mae' ] )\n","    # model.compile( loss='mean_squared_error', optimizer=keras.optimizers.Adam( LR ), metrics=['mae' ] )\n","    model.compile( loss='mean_squared_error', optimizer='adam', metrics=['mae' ] )\n","    return model\n","\n","\n","\n","def hyperparam_optimization( x, y ) :\n","    nBits = x.shape[1]\n","    frac_test = 0.3\n","    x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=frac_test )\n","\n","    TRAIN_EPOCHS = 20\n","    MAX_TRIALS=20\n","    EXECUTIONS_PER_TRIAL = 5\n","\n","    b_tuner = BayesianOptimization(\n","        make_optimizer_model(nBits),\n","        objective = 'val_mean_squared_error',\n","        max_trials = MAX_TRIALS,\n","        executions_per_trial=EXECUTIONS_PER_TRIAL,\n","        directory='test_dir',\n","        project_name='tune_optimizer',\n","        seed=1\n","    )\n","    b_tuner.search_space_summary()\n","\n","    b_tuner.search( x=x_train, y=y_train, epochs=TRAIN_EPOCHS, validation_data=(x_test, y_test))\n","    b_tuner.results_summary()\n","    best_model = b_tuner.get_best_models()[0]\n","\n","    return best_model\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIL2P8jZjLzt","colab_type":"code","colab":{}},"source":["def train_chembl_predict_biocides( x, y, path ) :\n","    nBits = x.shape[1]\n","\n","    strategy = tf.distribute.MirroredStrategy()\n","    # print('\\n===>Number of devices: {}\\n'.format(strategy.num_replicas_in_sync))\n","\n","    with strategy.scope() :\n","        model = make_model( nfeatures=nBits )\n","\n","    model = train( x, y, model, epochs = 10, batch = 64  )\n","\n","    sdfname = \"comp_182_ligand_prep_+_agonist.sd\"\n","    predict( model, path + sdfname )\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDpWTjjKHjYY","colab_type":"code","colab":{}},"source":["def main() :\n","    #config = tf.compat.v1.ConfigProto()\n","    #config.gpu_options.allow_growth = True\n","    #_ = tf.compat.v1.Session(config=config)\n","\n","    # hyperparam_optimization( x, y, model )\n","    # gridsearch( x, y, model )\n","    # model = qsar( x, y, model )\n","\n","    nBits = 128\n","    path = \"./drive/My Drive/ColabNotebooks/\"\n","    x, y = prepareMoleculeFingerprint( path, nBits=nBits )\n","\n","    # hyperparam_optimization( x, y )\n","    parameter_gridsearch( x, y )\n","    # train_chembl_predict_biocides( x, y, path )\n","\n","    return\n","\n","\n","\n","if __name__ == '__main__' :\n","    main()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XhX5znAa-fpc","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}